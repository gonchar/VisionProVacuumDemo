# Vision Pro Vacuum Demo

https://github.com/gonchar/VisionProVacuumDemo/assets/1416917/97ce2fd7-db31-41dd-bf70-1f9bef06f353

[View on Twitter](https://twitter.com/the_gonchar/status/1756441654507008079)

Source code for a demo project which showcases how to work with Apple Vision Pro and RealityKit, ARKit APIs.

Here I showcase how to work with 
* ARKit: head tracking, hand tracking, scene understanding
* Load & play sounds
* Process collisions
* Work with underlying mesh data using MTLBuffers
* I always enjoy with [Injection](https://github.com/johnno1962/InjectionIII) and on Apple Vision Pro it feels like you are a mage when you change the code and smth changes in front of you while your are wearing the device

I wish I had this opensource example before. Happy to share it with community.
